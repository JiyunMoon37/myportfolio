{
  "hash": "9db3eb403ed6cc36aa56558c4457ec45",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"LS 빅데이터 스쿨 HW8\"\nauthor : \"지윤\"\ndate : \"2024-09-10\"\ncategories : [bigdata]\njupyter: python3\n---\n\n\n### 기본코드\n\n::: {#551f309c .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom sklearn.metrics import f1_score\n```\n:::\n\n\n## 문제 1: 데이터 로드 및 로지스틱 회귀 모델 적합\n\n::: {#1f0aa50f .cell execution_count=2}\n``` {.python .cell-code}\n# 데이터 로드\n# 파일을 판다스로 읽기\nfile_path =\"C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/leukemia_remission.txt\"\n\n# 공백 또는 탭으로 구분된 데이터를 pandas DataFrame으로 불러오기\ndata = pd.read_csv(file_path, sep='\\t') # 공백으로 구분된 파일\n#data =  pd.read_table(\"C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/leukemia_remission.txt\", delimiter='\\t')\nprint(data.head())\n\n# 독립 변수와 종속 변수 정의\nX = data[['CELL', 'SMEAR', 'INFIL', 'LI', 'BLAST', 'TEMP']]\ny = data['REMISS']\n\n# 상수항 추가\nX = sm.add_constant(X)\n\n# 로지스틱 회귀 모델 적합\nmodel = sm.Logit(y, X).fit()\n\n# 회귀 표 작성\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   REMISS  CELL  SMEAR  INFIL   LI  BLAST  TEMP\n0       1   0.8   0.83   0.66  1.9   1.10  1.00\n1       1   0.9   0.36   0.32  1.4   0.74  0.99\n2       0   0.8   0.88   0.70  0.8   0.18  0.98\n3       0   1.0   0.87   0.87  0.7   1.05  0.99\n4       1   0.9   0.75   0.68  1.3   0.52  0.98\nOptimization terminated successfully.\n         Current function value: 0.399886\n         Iterations 10\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                 REMISS   No. Observations:                   27\nModel:                          Logit   Df Residuals:                       20\nMethod:                           MLE   Df Model:                            6\nDate:                Tue, 10 Sep 2024   Pseudo R-squ.:                  0.3718\nTime:                        10:42:46   Log-Likelihood:                -10.797\nconverged:                       True   LL-Null:                       -17.186\nCovariance Type:            nonrobust   LLR p-value:                   0.04670\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         64.2581     74.965      0.857      0.391     -82.670     211.187\nCELL          30.8301     52.135      0.591      0.554     -71.353     133.013\nSMEAR         24.6863     61.526      0.401      0.688     -95.903     145.275\nINFIL        -24.9745     65.281     -0.383      0.702    -152.923     102.974\nLI             4.3605      2.658      1.641      0.101      -0.849       9.570\nBLAST         -0.0115      2.266     -0.005      0.996      -4.453       4.430\nTEMP        -100.1734     77.753     -1.288      0.198    -252.567      52.220\n==============================================================================\n\nPossibly complete quasi-separation: A fraction 0.11 of observations can be\nperfectly predicted. This might indicate that there is complete\nquasi-separation. In this case some parameters will not be identified.\n```\n:::\n:::\n\n\n## 문제 2: 모델의 통계적 유의성 검정\n\n::: {#a76489c1 .cell execution_count=3}\n``` {.python .cell-code}\n# 모델의 유의성 평가\n# p-value 확인\np_values = model.pvalues\nprint(\"\\n각 변수의 p-value:\")\nprint(p_values)\n\n# 유의성 판단\nalpha = 0.05\nsignificant_vars = p_values[p_values < alpha].index.tolist()\nif significant_vars:\n    print(f\"\\n유의한 변수들: {significant_vars}\")\nelse:\n    print(\"\\n유의한 변수가 없습니다.\")\n\n# 예측 수행\n# 예측 확률 계산\npredicted_probabilities = model.predict(X)\n\n# 예측 클래스 결정 (임계값 0.5 사용)\npredicted_classes = (predicted_probabilities >= 0.5).astype(int)\n\n# 예측 결과 출력\ndata['Predicted_Probabilities'] = predicted_probabilities\ndata['Predicted_Classes'] = predicted_classes\n\nprint(\"\\n예측 결과:\")\nprint(data[['REMISS', 'Predicted_Probabilities', 'Predicted_Classes']].head())\n\n# 혼동 행렬 출력\nfrom sklearn.metrics import confusion_matrix\nconf_matrix = confusion_matrix(data['REMISS'], predicted_classes)\nprint(\"\\n혼동 행렬:\")\nprint(conf_matrix)\n\n# 정확도 계산\naccuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / conf_matrix.sum()\nprint(f\"\\n모델의 정확도: {accuracy:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n각 변수의 p-value:\nconst    0.391348\nCELL     0.554288\nSMEAR    0.688249\nINFIL    0.702039\nLI       0.100899\nBLAST    0.995940\nTEMP     0.197623\ndtype: float64\n\n유의한 변수가 없습니다.\n\n예측 결과:\n   REMISS  Predicted_Probabilities  Predicted_Classes\n0       1                 0.736412                  1\n1       1                 0.456316                  0\n2       0                 0.179508                  0\n3       0                 0.215175                  0\n4       1                 0.736896                  1\n\n혼동 행렬:\n[[15  3]\n [ 4  5]]\n\n모델의 정확도: 0.74\n```\n:::\n:::\n\n\n## 문제 3: 유의수준 0.2 기준으로 통계적으로 유의한 변수\n\n::: {#d30149ba .cell execution_count=4}\n``` {.python .cell-code}\n# 유의수준 0.2 기준으로 유의한 변수 확인\nalpha = 0.2\nsignificant_vars_0_2 = p_values[p_values < alpha].index.tolist()\n\nprint(f\"\\n유의수준 0.2에서 유의한 변수들: {significant_vars_0_2}\")\nprint(f\"유의한 변수의 개수: {len(significant_vars_0_2)}\")\n\n#유의수준 0.2에서 유의한 변수들: ['LI', 'TEMP']\n#유의한 변수의 개수: 2\n\n## 문제 4: 주어진 환자에 대한 오즈 계산\n# 환자 특성 정의\npatient_data = {\n    'const': 1,  # 상수항\n    'CELL': 0.65,\n    'SMEAR': 0.45,\n    'INFIL': 0.55,\n    'LI': 1.2,\n    'BLAST': 1.1,\n    'TEMP': 0.9\n}\n\n# 오즈 계산\nlog_odds = model.params.dot(pd.Series(patient_data))\nodds = np.exp(log_odds)\n\nprint(f\"\\n환자의 오즈: {odds:.4f}\")\n\n# 환자의 오즈: 0.0382\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n유의수준 0.2에서 유의한 변수들: ['LI', 'TEMP']\n유의한 변수의 개수: 2\n\n환자의 오즈: 0.0382\n```\n:::\n:::\n\n\n## 문제 5: 백혈병 세포가 관측되지 않은 확률 계산\n\n::: {#9b3d05a9 .cell execution_count=5}\n``` {.python .cell-code}\n# 예측 확률 계산\npredicted_probability = model.predict(pd.Series(patient_data))\nnon_observed_probability = 1 - predicted_probability\n\nprint(f\"\\n백혈병 세포가 관측되지 않은 확률: {non_observed_probability.values[0]:.4f}\")\n\n#백혈병 세포가 관측되지 않은 확률: 0.9632\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n백혈병 세포가 관측되지 않은 확률: 0.9632\n```\n:::\n:::\n\n\n## 문제 6: TEMP 변수의 계수와 설명\n\n::: {#c50ab95f .cell execution_count=6}\n``` {.python .cell-code}\n# TEMP 변수의 계수\ntemp_coefficient = model.params['TEMP']\nprint(f\"\\nTEMP 변수의 계수: {temp_coefficient:.4f}\")\n\n# TEMP의 영향 설명\nprint(\"TEMP 변수의 계수는 치료에 대한 영향력을 나타냅니다. 계수가 양수인 경우, TEMP가 증가할수록 백혈병 치료의 성공 확률이 증가하는 것을 의미합니다.\")\n\n#TEMP 변수의 계수: -100.1734\n#TEMP 변수의 계수는 치료에 대한 영향력을 나타냅니다. \n#계수가 양수인 경우, TEMP가 증가할수록 백혈병 치료의 성공 확률이 증가하는 것을 의미합니다.\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nTEMP 변수의 계수: -100.1734\nTEMP 변수의 계수는 치료에 대한 영향력을 나타냅니다. 계수가 양수인 경우, TEMP가 증가할수록 백혈병 치료의 성공 확률이 증가하는 것을 의미합니다.\n```\n:::\n:::\n\n\n## 문제 7: CELL 변수의 99% 오즈비에 대한 신뢰구간\n\n::: {#2c003bc2 .cell execution_count=7}\n``` {.python .cell-code}\n# CELL 변수의 오즈비 및 신뢰구간 계산\ncell_odds_ratio = np.exp(model.params['CELL'])\n\n# 99% 신뢰구간 계산\nconf_int = model.conf_int(alpha=0.01).loc['CELL']  # alpha=0.01로 99% 신뢰구간\ncell_conf_int = np.exp(conf_int)\n\nprint(f\"CELL 변수의 오즈비: {cell_odds_ratio:.4f}\")\nprint(f\"CELL 변수의 99% 신뢰구간: ({cell_conf_int[0]:.4e}, {cell_conf_int[1]:.4e})\")\n\n#CELL 변수의 99% 신뢰구간: (1.1673e-45, 5.1460e+71)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCELL 변수의 오즈비: 24508982903971.1094\nCELL 변수의 99% 신뢰구간: (1.1673e-45, 5.1460e+71)\n```\n:::\n:::\n\n\n## 문제 8: 로지스틱 회귀 모델의 예측 확률과 혼동 행렬\n\n::: {#858e47ce .cell execution_count=8}\n``` {.python .cell-code}\n# 예측 확률 계산\ndata['Predicted_Probabilities'] = model.predict(X)\ndata['Predicted_Classes'] = (data['Predicted_Probabilities'] >= 0.5).astype(int)\n\n# 혼동 행렬 계산\nconf_matrix = confusion_matrix(data['REMISS'], data['Predicted_Classes'])\nprint(\"\\n혼동 행렬:\")\nprint(conf_matrix)\n\n#혼동 행렬:\n#[[15  3]\n#[ 4  5]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n혼동 행렬:\n[[15  3]\n [ 4  5]]\n```\n:::\n:::\n\n\n## 문제 9: 모델의 Accuracy 계산\n\n::: {#b4c97039 .cell execution_count=9}\n``` {.python .cell-code}\n# 정확도 계산\naccuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / conf_matrix.sum()\nprint(f\"\\n모델의 Accuracy: {accuracy:.2f}\")\n\n#모델의 Accuracy: 0.74\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n모델의 Accuracy: 0.74\n```\n:::\n:::\n\n\n## 문제 10: F1 Score 계산 \n\n::: {#0d58d075 .cell execution_count=10}\n``` {.python .cell-code}\n# F1 Score 계산\nf1 = f1_score(data['REMISS'], data['Predicted_Classes'])\nprint(f\"\\n모델의 F1 Score: {f1:.4f}\")\n\n#모델의 F1 Score: 0.5882\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n모델의 F1 Score: 0.5882\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}